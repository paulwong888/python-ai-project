services:
  llamafactory:
    image: kenneth850511/llamafactory
    container_name: llamafactory
    volumes:
      - /home/paul/.cache/huggingface:/root/.cache/huggingface
      - ../../ms_cache:/root/.cache/modelscope
      - ../../om_cache:/root/.cache/openmind
      - ../../data:/app/data
      - ../../output:/app/output
      - ../../saves:/app/saves
      - /etc/localtime:/etc/localtime:ro
    ports:
      - "7861:7860"
      - "8000:8000"
    ipc: host
    tty: true
    shm_size: '16gb'
    stdin_open: true
    command: bash
    deploy:
      resources:
        reservations:
          devices:
          - driver: nvidia
            count: "all"
            capabilities: [gpu]
    restart: unless-stopped
