# model params
base_model: /home/paul/.cache/huggingface/models/unsloth--Meta-Llama-3.1-8B
model_type: LlamaForCausalLM
tokenizer_type: PreTrainedTokenizerFast

# dataset params
datasets:
  - path: jaydenccc/AI_Storyteller_Dataset
    type:
      system_prompt: ""
      field_system: system
      field_instruction: synopsis
      field_output: short_story
      format: "<|user|>\n {instruction} </s>\n<|assistant|>"
      no_input_format: "<|user|>\n {instruction} </s>\n<|assistant|>"

output_dir: ./models/Llama3_Storyteller

# model params
sequence_length: 512
bf16: auto
bf32: false

# training params
batch_size: 1
micro_batch_size: 1
num_epochs: 4
optimize: adamw_bnb_8bit
learning_rate: 0.0002

logging_steps: 1